{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This notebook runs the individual steps of the provided Snakemake pipeline. This may be useful for understanding the functions, but it is highly recommended to use Snakemake to run the pipeline on screening data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukefunk/packages/NatureProtocols/venv/lib/python3.7/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import ops\n",
    "from ops.imports_ipython import *\n",
    "from ops.paper.cell_idr import setup_example\n",
    "\n",
    "# runs example from repository directory\n",
    "home = os.path.dirname(os.path.dirname(ops.__file__))\n",
    "os.chdir(home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linked barcodes.csv\n",
      "Linked config.yaml\n",
      "Linked Snakefile\n",
      "Downloading 10 files from Cell-IDR with command: ascp -T -l200m -P 33001 -i /Users/lukefunk/packages/NatureProtocols/resources/asperaweb_id_dsa.openssh --file-pair-list=example/ascp_download_list.txt --mode=recv --user=idr0071 --host=fasp.ebi.ac.uk example\n",
      "Setup complete.\n",
      "To run the example snakemake pipeline, execute the following:\n",
      "cd example\n",
      "snakemake --cores --configfile=config.yaml\n"
     ]
    }
   ],
   "source": [
    "# if ascp is in your path use ascp='ascp', otherwise use the path to the ascp executable\n",
    "setup_example('example',ascp='ascp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(home, 'example'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "barcodes = pd.read_csv('barcodes.csv')\n",
    "\n",
    "THRESHOLD_READS = 50\n",
    "THRESHOLD_DAPI = 200\n",
    "THRESHOLD_CELL = 600\n",
    "NUCLEUS_AREA = 40, 400\n",
    "WILDCARDS = dict(well='A1', tile=102)\n",
    "\n",
    "SBS_CYCLES = [1, 2, 3, 4, 5, 7, 8, 9, 10]\n",
    "\n",
    "LUTS = [\n",
    "    ops.io.GRAY,\n",
    "    ops.io.GREEN,\n",
    "    ops.io.RED,\n",
    "    ops.io.MAGENTA,\n",
    "    ops.io.CYAN\n",
    "]\n",
    "\n",
    "DISPLAY_RANGES = [\n",
    "    [500, 15000],\n",
    "    [100, 10000],\n",
    "    [100, 20000],\n",
    "    [100, 8000],\n",
    "    [100, 6000]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experimentC/input/10X_c1-SBS-1/10X_c1-SBS-1_A1_Tile-102.sbs.tif\n",
      "experimentC/input/10X_c2-SBS-2/10X_c2-SBS-2_A1_Tile-102.sbs.tif\n",
      "experimentC/input/10X_c3-SBS-3/10X_c3-SBS-3_A1_Tile-102.sbs.tif\n",
      "experimentC/input/10X_c4-SBS-4/10X_c4-SBS-4_A1_Tile-102.sbs.tif\n",
      "experimentC/input/10X_c5-SBS-5/10X_c5-SBS-5_A1_Tile-102.sbs.tif\n",
      "experimentC/input/10X_c7-SBS-7/10X_c7-SBS-7_A1_Tile-102.sbs.tif\n",
      "experimentC/input/10X_c8-SBS-8/10X_c8-SBS-8_A1_Tile-102.sbs.tif\n",
      "experimentC/input/10X_c9-SBS-9/10X_c9-SBS-9_A1_Tile-102.sbs.tif\n",
      "experimentC/input/10X_c10-SBS-10/10X_c10-SBS-10_A1_Tile-102.sbs.tif\n"
     ]
    }
   ],
   "source": [
    "search = 'experimentC/input/*/10X*{well}_Tile-{tile}.sbs.tif'.format(**WILDCARDS)\n",
    "input_files = natsorted(glob(search))\n",
    "for f in input_files:\n",
    "    print(f)\n",
    "\n",
    "# used to format output filenames\n",
    "description = parse(input_files[0])\n",
    "description['subdir'] = 'experimentC/process_ipynb'\n",
    "description.pop('cycle');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experimentC/input/10X_c0-DAPI-p65ab/10X_c0-DAPI-p65ab_A1_Tile-102.phenotype.tif\n"
     ]
    }
   ],
   "source": [
    "ph_search = 'experimentC/input/*/10X*{well}_Tile-{tile}.phenotype.tif'.format(**WILDCARDS)\n",
    "ph_input_files = natsorted(glob(ph_search))\n",
    "for f in ph_input_files:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load, align, apply Laplacian-of-Gaussian filter (log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([read(f) for f in input_files])\n",
    "aligned = Snake._align_SBS(data)\n",
    "save(name(description, tag='aligned'), aligned, display_ranges=DISPLAY_RANGES, luts=LUTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_data = read(ph_input_files[0])\n",
    "ph_aligned = Snake._align_by_DAPI(data_1=data[0], data_2=ph_data)\n",
    "save(name(description, tag='phenotype_aligned'),ph_aligned, luts=LUTS[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loged = Snake._transform_log(aligned, skip_index=0)\n",
    "save(name(description, tag='log'), loged, display_ranges=DISPLAY_RANGES, luts=LUTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxed = Snake._max_filter(loged, 3, remove_index=0)\n",
    "save(name(description, tag='maxed'), maxed, display_ranges=DISPLAY_RANGES[1:], luts=LUTS[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### detect candidate reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = Snake._compute_std(loged, remove_index=0)\n",
    "save(name(description, tag='std'), std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks = Snake._find_peaks(std)\n",
    "save(name(description, tag='peaks'), peaks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### segment nuclei and cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclei = Snake._segment_nuclei(data[0], THRESHOLD_DAPI,\n",
    " area_min=NUCLEUS_AREA[0], area_max=NUCLEUS_AREA[1])\n",
    "\n",
    "save(name(description, tag='nuclei'), nuclei, compress=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = Snake._segment_cells(data[0], nuclei, THRESHOLD_CELL)\n",
    "save(name(description, tag='cells'), cells, compress=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract base intensity, call reads, assign to cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "df_bases = Snake._extract_bases(maxed, peaks, cells, \n",
    "                        THRESHOLD_READS, wildcards=WILDCARDS)\n",
    "df_bases.to_csv(name(description, tag='bases', ext='csv'), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reads = Snake._call_reads(df_bases, peaks=peaks)\n",
    "filename = name(description, tag='reads', ext='csv')\n",
    "df_reads.to_csv(filename, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read from csv to match numerical precision of snakemake pipeline\n",
    "df_reads = pd.read_csv(filename) \n",
    "df_cells = Snake._call_cells(df_reads)\n",
    "df_cells.to_csv(name(description, tag='cells', ext='csv'), index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract phenotypes and combine with called cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phenotype = Snake._extract_named_cell_nucleus_features(\n",
    "    data=ph_aligned,\n",
    "    cells=cells,\n",
    "    nuclei=nuclei,\n",
    "    nucleus_features=[\n",
    "        'label', # required to join SBS and phenotype data\n",
    "        'i',\n",
    "        'j',\n",
    "        'area',\n",
    "        'dapi_gfp_corr',\n",
    "        'dapi_max',\n",
    "        'dapi_mean',\n",
    "        'dapi_median',\n",
    "        'gfp_max',\n",
    "        'gfp_mean',\n",
    "        'gfp_median',\n",
    "    ],\n",
    "    cell_features=['label', 'area'],\n",
    "    wildcards=WILDCARDS\n",
    ")\n",
    "df_phenotype.to_csv(name(description, tag='phenotype', ext='csv'), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = Snake._merge_sbs_phenotype(\n",
    "    sbs_tables=df_cells, \n",
    "    phenotype_tables=df_phenotype,\n",
    "    barcode_table=barcodes, \n",
    "    sbs_cycles=SBS_CYCLES\n",
    ")\n",
    "df_combined.to_csv(name(description, tag='combined', ext='csv'), index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### annotated SBS images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last channel annotates base calls\n",
    "annotate_luts = LUTS + [ops.annotate.GRMC, ops.io.GRAY]\n",
    "annotate_display_ranges = [(a/4, b/4) for a,b in DISPLAY_RANGES] + [[0, 4]]\n",
    "annotate_SBS = Snake._annotate_SBS(log=loged, df_reads=df_reads)\n",
    "save(name(description, tag='annotate_SBS'), annotate_SBS,\n",
    "     display_ranges=annotate_display_ranges, luts=annotate_luts, compress=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second-to-last channel annotates base calls (notches are mapped reads, pluses are unmapped reads)\n",
    "# last channel encodes peaks value\n",
    "annotate_extra_luts = LUTS + [ops.annotate.GRMC, ops.io.GRAY, ops.io.GRAY]\n",
    "annotate_extra_display_ranges = (\n",
    "    [(a/4, b/4) for a,b in DISPLAY_RANGES]\n",
    "    +[[0, 4], [0, THRESHOLD_READS*4], [0, 30]]\n",
    ")\n",
    "annotate_SBS_extra = Snake._annotate_SBS_extra(\n",
    "    log=loged,\n",
    "    peaks=peaks,\n",
    "    df_reads=df_reads,\n",
    "    barcode_table=barcodes,\n",
    "    sbs_cycles=SBS_CYCLES\n",
    ")\n",
    "save(name(description, tag='annotate_SBS_extra'), annotate_SBS_extra,\n",
    "     display_ranges=annotate_extra_display_ranges[1:], luts=annotate_extra_luts[1:], compress=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
